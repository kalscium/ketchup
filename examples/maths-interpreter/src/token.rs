//! Lexer and token definitions

use logos::Logos;
use crate::error::Error;

/// A token generated by the lexer
#[derive(Debug, Clone, Logos, PartialEq)]
#[logos(error = Error)]
#[logos(skip r"[ \t\r\n\f]+")] // whitespace
#[logos(skip r"\/\/[^\n\r]*")] // `//` comments
#[logos(skip r"#[^\n\r]*")] // `#` comments
#[logos(skip r"\/\*[^\*\/]*\*\/")] // multi-line comments
pub enum Token {
    // Literals
    /// A number literal
    #[regex(r"[0-9]+", |lex| lex.slice().parse::<f64>().unwrap())]
    #[regex(r"[0-9]+\.[0-9]+f", |lex| lex.slice()[1..lex.slice().len()-1].parse::<f64>().unwrap())]
    Number(f64),

    // Symbols
    //
    // note: meaning shouldn't be encoded at this point, that's the parser's job
    #[token("+")]
    Plus,
    #[token("-")]
    Dash,
    #[token("*")]
    Star,
    #[token("/")]
    Slash,

    // Parentheses
    #[token("(")]
    LParen,
    #[token(")")]
    RParen,
}
